{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 3: Practical Applications & Best Practices\n",
    "\n",
    "In the previous notebooks, we learned the fundamentals and advanced techniques of dictionary serialization. This final notebook focuses on real-world applications, crucial security considerations, and best practices for writing robust and maintainable serialization code.\n",
    "\n",
    "**Learning Objectives:**\n",
    "*   See practical examples: configuration management, API data exchange, inventory systems.\n",
    "*   Understand the security risks associated with deserialization (especially Pickle).\n",
    "*   Learn the importance of input validation.\n",
    "*   Summarize best practices: choosing formats, versioning, error handling, testing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Practical Applications and Best Practices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Real-World Applications of Dictionary Serialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Configuration Management**\n",
    "\n",
    "Dictionaries are ideal for structuring application settings. Serializing them to JSON or YAML makes configuration easy to read, write, and manage.\n",
    "\n",
    "*Format Choice:* YAML is often preferred for its readability and support for comments, while JSON is simpler and universally supported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pyyaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: Requires PyYAML: pip install pyyaml\n",
    "try:\n",
    "    import yaml\n",
    "    import os\n",
    "    from pprint import pprint\n",
    "\n",
    "    config_file = 'app_config.yaml'\n",
    "\n",
    "    default_config = {\n",
    "        'database': {\n",
    "            'type': 'postgresql',\n",
    "            'host': 'localhost',\n",
    "            'port': 5432,\n",
    "            'user': 'dev_user',\n",
    "            'password': 'change_me'\n",
    "        },\n",
    "        'logging': {\n",
    "            'level': 'INFO', # Options: DEBUG, INFO, WARNING, ERROR\n",
    "            'file': '/var/log/app.log'\n",
    "        },\n",
    "        'features': {\n",
    "            'enable_beta': False,\n",
    "            'max_users': 1000\n",
    "        },\n",
    "        'api_keys': {\n",
    "            'service_a': None # Expect key to be provided externally\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # --- Save Default Configuration ---\n",
    "    print(f\"Saving default config to {config_file}...\")\n",
    "    try:\n",
    "        with open(config_file, 'w') as f:\n",
    "            # Use dump for nice formatting and comments (though comments aren't added here)\n",
    "            yaml.dump(default_config, f, default_flow_style=False, sort_keys=False)\n",
    "        print(\"Default config saved.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving config: {e}\")\n",
    "        \n",
    "    # --- Load Configuration --- \n",
    "    print(f\"\\nLoading config from {config_file}...\")\n",
    "    loaded_config = {}\n",
    "    try:\n",
    "        with open(config_file, 'r') as f:\n",
    "            # Use safe_load to avoid potential security issues with arbitrary code execution\n",
    "            loaded_config = yaml.safe_load(f)\n",
    "        print(\"Config loaded successfully:\")\n",
    "        pprint(loaded_config)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Config file {config_file} not found. Using empty config.\")\n",
    "    except yaml.YAMLError as e:\n",
    "        print(f\"Error parsing YAML config file {config_file}: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred loading config: {e}\")\n",
    "\n",
    "    # --- Simulate Overriding with Environment Variables (Common Practice) ---\n",
    "    print(\"\\nChecking for environment variable overrides...\")\n",
    "    # Example: export DB_HOST=prod.db.server.com\n",
    "    # Example: export LOG_LEVEL=DEBUG\n",
    "    db_host_override = os.environ.get('DB_HOST')\n",
    "    log_level_override = os.environ.get('LOG_LEVEL')\n",
    "\n",
    "    if db_host_override and 'database' in loaded_config:\n",
    "        print(f\"Overriding DB host with: {db_host_override}\")\n",
    "        loaded_config['database']['host'] = db_host_override\n",
    "\n",
    "    if log_level_override and 'logging' in loaded_config:\n",
    "        print(f\"Overriding log level with: {log_level_override}\")\n",
    "        loaded_config['logging']['level'] = log_level_override\n",
    "        \n",
    "    print(\"\\nFinal Config (potentially overridden):\")\n",
    "    pprint(loaded_config)\n",
    "\n",
    "    # Clean up config file\n",
    "    if os.path.exists(config_file):\n",
    "        os.remove(config_file)\n",
    "        print(f\"\\nCleaned up {config_file}\")\n",
    "\n",
    "except ImportError:\n",
    "    print(\"PyYAML not installed. Run 'pip install pyyaml' to run this cell.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Data Exchange in APIs**\n",
    "\n",
    "JSON is the de facto standard for sending data to and receiving data from web APIs (REST, GraphQL, etc.). Python dictionaries are easily converted to/from JSON for these interactions.\n",
    "\n",
    "*Requires Installation:* `pip install requests`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: Requires the 'requests' library: pip install requests\n",
    "try:\n",
    "    import requests\n",
    "    import json\n",
    "    from pprint import pprint\n",
    "\n",
    "    # Example: Creating a new user via a hypothetical API endpoint\n",
    "    api_endpoint = 'https://jsonplaceholder.typicode.com/posts' # Using a public test API\n",
    "\n",
    "    # Prepare data as a Python dictionary\n",
    "    new_post_data = {\n",
    "        'title': 'My New Blog Post',\n",
    "        'body': 'This is the content of the post using serialization!',\n",
    "        'userId': 101 # Example user ID\n",
    "    }\n",
    "    \n",
    "    print(\"Dictionary to send:\")\n",
    "    pprint(new_post_data)\n",
    "\n",
    "    # --- Send POST request with JSON payload ---\n",
    "    try:\n",
    "        # The 'json' parameter in requests automatically serializes the dict to JSON \n",
    "        # and sets the 'Content-Type: application/json' header.\n",
    "        response = requests.post(api_endpoint, json=new_post_data)\n",
    "        \n",
    "        # Check if the request was successful (e.g., status code 201 Created)\n",
    "        response.raise_for_status() # Raises an exception for bad status codes (4xx or 5xx)\n",
    "        \n",
    "        print(f\"\\nAPI Request Successful! Status Code: {response.status_code}\")\n",
    "\n",
    "        # --- Deserialize the JSON response --- \n",
    "        # The response.json() method automatically deserializes the JSON response body\n",
    "        response_data = response.json() \n",
    "        \n",
    "        print(\"\\nDeserialized API Response (Dictionary):\")\n",
    "        pprint(response_data)\n",
    "        \n",
    "        # Verify we got an ID back (specific to this test API)\n",
    "        assert 'id' in response_data\n",
    "        print(f\"\\nSuccessfully created resource with ID: {response_data.get('id')}\")\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"\\nAPI request failed: {e}\")\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"\\nFailed to decode API response: {e}\")\n",
    "        print(f\"Raw response text: {response.text[:200]}...\") # Show part of the raw response\n",
    "    except Exception as e:\n",
    "        print(f\"\\nAn unexpected error occurred: {e}\")\n",
    "\n",
    "except ImportError:\n",
    "    print(\"requests library not installed. Run 'pip install requests' to run this cell.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Simple Inventory Management System**\n",
    "\n",
    "This example shows using JSON serialization to persist the state of a simple inventory stored in a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from pprint import pprint\n",
    "\n",
    "class InventorySystem:\n",
    "    def __init__(self, storage_file='inventory_data.json'):\n",
    "        self.storage_file = storage_file\n",
    "        self.inventory = self._load_inventory()\n",
    "        print(f\"Inventory system initialized. Loaded {len(self.inventory)} items from {self.storage_file}\")\n",
    "\n",
    "    def _load_inventory(self):\n",
    "        \"\"\"Loads inventory from the JSON file.\"\"\"\n",
    "        if os.path.exists(self.storage_file):\n",
    "            try:\n",
    "                with open(self.storage_file, 'r') as f:\n",
    "                    data = json.load(f)\n",
    "                    # Basic validation: check if it's a dictionary\n",
    "                    if isinstance(data, dict):\n",
    "                        return data\n",
    "                    else:\n",
    "                        print(f\"Warning: Data in {self.storage_file} is not a dictionary. Starting empty.\")\n",
    "                        return {}\n",
    "            except json.JSONDecodeError:\n",
    "                print(f\"Warning: Could not decode JSON from {self.storage_file}. Starting empty.\")\n",
    "                return {}\n",
    "            except Exception as e:\n",
    "                print(f\"Warning: Error loading inventory from {self.storage_file}: {e}. Starting empty.\")\n",
    "                return {}\n",
    "        return {} # Return empty dict if file doesn't exist\n",
    "\n",
    "    def save_inventory(self):\n",
    "        \"\"\"Saves the current inventory to the JSON file.\"\"\"\n",
    "        try:\n",
    "            with open(self.storage_file, 'w') as f:\n",
    "                # Use indent for readability\n",
    "                json.dump(self.inventory, f, indent=2)\n",
    "            # print(f\"Inventory saved to {self.storage_file}\") # Optional: uncomment for verbose logging\n",
    "        except Exception as e:\n",
    "            print(f\"Error saving inventory to {self.storage_file}: {e}\")\n",
    "\n",
    "    def add_product(self, product_id, name, quantity, price):\n",
    "        if product_id in self.inventory:\n",
    "            print(f\"Warning: Product ID {product_id} already exists. Use update methods.\")\n",
    "            return False\n",
    "        if not isinstance(quantity, int) or quantity < 0:\n",
    "             print(f\"Error: Quantity ({quantity}) must be a non-negative integer.\")\n",
    "             return False\n",
    "        if not isinstance(price, (int, float)) or price < 0:\n",
    "             print(f\"Error: Price ({price}) must be a non-negative number.\")\n",
    "             return False\n",
    "             \n",
    "        self.inventory[product_id] = {\n",
    "            'name': str(name),\n",
    "            'quantity': quantity,\n",
    "            'price': float(price)\n",
    "        }\n",
    "        print(f\"Added product: {product_id} - {name}\")\n",
    "        self.save_inventory()\n",
    "        return True\n",
    "\n",
    "    def update_quantity(self, product_id, quantity_change):\n",
    "        if product_id in self.inventory:\n",
    "            new_quantity = self.inventory[product_id]['quantity'] + quantity_change\n",
    "            if new_quantity < 0:\n",
    "                print(f\"Error: Quantity cannot drop below zero for {product_id}.\")\n",
    "                return False\n",
    "            self.inventory[product_id]['quantity'] = new_quantity\n",
    "            change_str = f\"Increased by {quantity_change}\" if quantity_change > 0 else f\"Decreased by {-quantity_change}\"\n",
    "            print(f\"Updated quantity for {product_id}: {change_str}. New quantity: {new_quantity}\")\n",
    "            self.save_inventory()\n",
    "            return True\n",
    "        else:\n",
    "            print(f\"Error: Product ID {product_id} not found.\")\n",
    "            return False\n",
    "\n",
    "    def get_product(self, product_id):\n",
    "        return self.inventory.get(product_id) # Returns None if not found\n",
    "        \n",
    "    def display_inventory(self):\n",
    "        print(\"\\nCurrent Inventory:\")\n",
    "        if not self.inventory:\n",
    "            print(\"  (Empty)\")\n",
    "            return\n",
    "        pprint(self.inventory)\n",
    "\n",
    "# --- Usage Example ---\n",
    "inventory_file = 'inventory_data.json'\n",
    "# Ensure clean start for demo\n",
    "if os.path.exists(inventory_file):\n",
    "    os.remove(inventory_file)\n",
    "\n",
    "inventory_system = InventorySystem(storage_file=inventory_file)\n",
    "inventory_system.display_inventory()\n",
    "\n",
    "print(\"\\n--- Performing operations ---\")\n",
    "inventory_system.add_product('LAP001', 'Laptop Pro 15\"', 25, 1299.99)\n",
    "inventory_system.add_product('MOU007', 'Wireless Mouse', 150, 19.50)\n",
    "inventory_system.add_product('KEY003', 'Mechanical Keyboard', 75, 89.00)\n",
    "\n",
    "inventory_system.update_quantity('LAP001', -5) # Sold 5 laptops\n",
    "inventory_system.update_quantity('MOU007', 50) # Received 50 mice\n",
    "inventory_system.update_quantity('XYZ999', 10) # Try updating non-existent product\n",
    "inventory_system.add_product('MON001', '27\" 4K Monitor', -5, 399.00) # Try adding with invalid quantity\n",
    "\n",
    "inventory_system.display_inventory()\n",
    "\n",
    "print(\"\\n--- Retrieving a product ---\")\n",
    "product = inventory_system.get_product('KEY003')\n",
    "if product:\n",
    "    print(f\"Details for KEY003:\")\n",
    "    pprint(product)\n",
    "\n",
    "# --- Simulate script ending and restarting ---\n",
    "print(\"\\n--- Simulating restart: Loading inventory again ---\")\n",
    "inventory_system_restarted = InventorySystem(storage_file=inventory_file)\n",
    "inventory_system_restarted.display_inventory()\n",
    "\n",
    "# Final check: verify data persisted\n",
    "assert inventory_system_restarted.get_product('LAP001')['quantity'] == 20\n",
    "assert inventory_system_restarted.get_product('MOU007')['quantity'] == 200\n",
    "\n",
    "# Clean up inventory file\n",
    "if os.path.exists(inventory_file):\n",
    "    os.remove(inventory_file)\n",
    "    print(f\"\\nCleaned up {inventory_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Security Considerations\n",
    "\n",
    "**Deserialization can be dangerous**, especially when processing data from untrusted sources (e.g., user uploads, external APIs).\n",
    "\n",
    "**1. Pickle Security Risks**\n",
    "\n",
    "`pickle.loads()` can be tricked into executing arbitrary code embedded within the pickled data. This is a major vulnerability.\n",
    "\n",
    "**Rule: NEVER unpickle data from untrusted sources.**\n",
    "\n",
    "Use safer formats like JSON for data exchange with external systems or users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "import json\n",
    "\n",
    "# --- Example of potentially malicious pickle data --- \n",
    "# This data, when unpickled, attempts to run the 'echo' command.\n",
    "# On Linux/macOS, it might print 'Malicious payload executed!' to the console.\n",
    "# On Windows, 'echo' is usually harmless, but 'os.system' could run *any* command.\n",
    "\n",
    "# Constructing the malicious payload (for demonstration ONLY - DO NOT RUN blindly)\n",
    "# This creates pickle data that calls os.system('echo Malicious payload executed!')\n",
    "malicious_command = \"echo Malicious payload executed!\"\n",
    "class PickleRCE:\n",
    "    def __reduce__(self):\n",
    "        return (os.system, (malicious_command,))\n",
    "\n",
    "malicious_pickle_data = pickle.dumps(PickleRCE())\n",
    "\n",
    "print(\"--- WARNING: Demonstrating Unpickling Risk ---\")\n",
    "print(\"The following line attempts to unpickle data that executes a command.\")\n",
    "print(\"It's designed to be relatively harmless ('echo'), but shows the potential danger.\\n\")\n",
    "\n",
    "try:\n",
    "    # *** THIS IS THE DANGEROUS OPERATION ***\n",
    "    # Suppressing output for safety in automated environments, \n",
    "    # but the os.system call *is* attempted.\n",
    "    print(\"Attempting pickle.loads(malicious_pickle_data)...\")\n",
    "    result = pickle.loads(malicious_pickle_data)\n",
    "    print(\"\\nUnpickling finished. Check console output if 'echo' command ran.\")\n",
    "    # In a real attack, the command could be 'rm -rf /' or download malware.\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\nUnpickling failed (this might happen depending on environment): {e}\")\n",
    "\n",
    "# --- Safer Alternative: JSON ---\n",
    "print(\"\\n--- Using JSON (Safe Alternative) ---\")\n",
    "# JSON contains only data, not executable code.\n",
    "safe_data_string = '{\"command\": \"echo Malicious payload executed!\", \"is_safe\": true}'\n",
    "\n",
    "try:\n",
    "    loaded_safe_data = json.loads(safe_data_string)\n",
    "    print(\"JSON data loaded safely:\")\n",
    "    pprint(loaded_safe_data)\n",
    "    # You would then explicitly decide how to handle 'loaded_safe_data['command']',\n",
    "    # rather than it being executed automatically.\n",
    "except json.JSONDecodeError as e:\n",
    "    print(f\"Error decoding JSON: {e}\")\n",
    "\n",
    "print(\"\\nConclusion: Avoid pickle.loads() with data from outside your direct control.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Input Validation**\n",
    "\n",
    "Even with safe formats like JSON, always validate the *structure* and *content* of deserialized data before using it. Assume external data might be malformed, missing required fields, or contain invalid values.\n",
    "\n",
    "Libraries like `jsonschema` can help validate data against a predefined structure.\n",
    "\n",
    "*Requires Installation:* `pip install jsonschema`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install jsonschema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: Requires jsonschema: pip install jsonschema\n",
    "try:\n",
    "    import json\n",
    "    from jsonschema import validate\n",
    "    from jsonschema.exceptions import ValidationError\n",
    "    from pprint import pprint\n",
    "\n",
    "    # --- Define a Schema for Expected User Data --- \n",
    "    # This schema describes the expected structure and types\n",
    "    user_schema = {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"userId\": {\"type\": \"string\", \"pattern\": \"^[a-zA-Z0-9_-]{3,16}$\"}, # Alphanumeric, underscore, hyphen, 3-16 chars\n",
    "            \"email\": {\"type\": \"string\", \"format\": \"email\"}, # Use built-in email format check\n",
    "            \"displayName\": {\"type\": \"string\", \"minLength\": 1, \"maxLength\": 50},\n",
    "            \"roles\": {\n",
    "                \"type\": \"array\",\n",
    "                \"items\": {\"type\": \"string\", \"enum\": [\"user\", \"editor\", \"admin\"]} # Must be one of these roles\n",
    "            },\n",
    "            \"preferences\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"theme\": {\"type\": \"string\", \"enum\": [\"light\", \"dark\"]},\n",
    "                    \"notifications\": {\"type\": \"boolean\"}\n",
    "                },\n",
    "                \"required\": [\"theme\"]\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"userId\", \"email\", \"roles\"] # These fields must be present\n",
    "    }\n",
    "\n",
    "    # --- Example Incoming Data Payloads --- \n",
    "    valid_payload = '''\n",
    "    {\n",
    "        \"userId\": \"alice_k\",\n",
    "        \"email\": \"alice.k@example.com\",\n",
    "        \"displayName\": \"Alice K.\",\n",
    "        \"roles\": [\"user\", \"editor\"],\n",
    "        \"preferences\": {\n",
    "            \"theme\": \"dark\",\n",
    "            \"notifications\": true\n",
    "        }\n",
    "    }\n",
    "    '''\n",
    "\n",
    "    invalid_payload_missing_field = '''\n",
    "    {\n",
    "        \"userId\": \"bob_m\", \n",
    "        \"displayName\": \"Bob M.\",\n",
    "        \"roles\": [\"user\"]\n",
    "        // Missing 'email' which is required\n",
    "    }\n",
    "    '''\n",
    "    \n",
    "    invalid_payload_bad_type = '''\n",
    "    {\n",
    "        \"userId\": \"charlie_d\",\n",
    "        \"email\": \"charlie.d@example.com\",\n",
    "        \"roles\": \"admin\" // Should be an array, not a string\n",
    "    }\n",
    "    '''\n",
    "    \n",
    "    invalid_payload_bad_value = '''\n",
    "    {\n",
    "        \"userId\": \"dave**\", // Invalid character in userId\n",
    "        \"email\": \"dave@\", // Invalid email format\n",
    "        \"roles\": [\"user\", \"guest\"] // 'guest' is not in the allowed enum\n",
    "    }\n",
    "    '''\n",
    "    \n",
    "    payloads_to_test = {\n",
    "        \"Valid Payload\": valid_payload,\n",
    "        \"Missing Required Field ('email')\": invalid_payload_missing_field,\n",
    "        \"Incorrect Type ('roles')\": invalid_payload_bad_type,\n",
    "        \"Invalid Values ('userId', 'email', 'roles')\": invalid_payload_bad_value\n",
    "    }\n",
    "\n",
    "    # --- Process and Validate Each Payload --- \n",
    "    for name, payload_str in payloads_to_test.items():\n",
    "        print(f\"\\n--- Testing: {name} ---\")\n",
    "        try:\n",
    "            # 1. Deserialize the JSON string\n",
    "            data = json.loads(payload_str)\n",
    "            print(\"Successfully deserialized JSON.\")\n",
    "            \n",
    "            # 2. Validate against the schema\n",
    "            validate(instance=data, schema=user_schema)\n",
    "            print(\"Schema validation PASSED.\")\n",
    "            # Proceed with using the validated 'data' dictionary\n",
    "            # print(\"Validated Data:\")\n",
    "            # pprint(data)\n",
    "\n",
    "        except json.JSONDecodeError as e:\n",
    "            # Handle cases where the input isn't even valid JSON\n",
    "            print(f\"Validation FAILED: Invalid JSON format - {e}\")\n",
    "        except ValidationError as e:\n",
    "            # Handle schema validation errors\n",
    "            print(f\"Validation FAILED: Schema validation error - {e.message}\")\n",
    "            # You might want to log e.path, e.validator, e.schema_path for more details\n",
    "        except Exception as e:\n",
    "            # Handle other unexpected errors\n",
    "            print(f\"Validation FAILED: An unexpected error occurred - {e}\")\n",
    "\n",
    "except ImportError:\n",
    "    print(\"jsonschema not installed. Run 'pip install jsonschema' to run this cell.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best Practices for Dictionary Serialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Choose the Right Format for Your Needs**\n",
    "\n",
    "*   **JSON:** Interoperability, web APIs, human-readable simple data.\n",
    "*   **Pickle:** Python-only, complex objects, caching, performance (but beware security).\n",
    "*   **MessagePack/Protocol Buffers:** Performance-critical, binary, compact size.\n",
    "*   **YAML:** Configuration files, human readability, comments.\n",
    "*   **HDF5:** Very large numerical data (often within dict values), partial I/O, scientific computing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Handle Versioning**\n",
    "\n",
    "If the structure of your serialized dictionaries might change over time, include a version marker in the data. When deserializing, check the version to apply appropriate logic or migration steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def serialize_data_v1(data):\n",
    "    # Original V1 format\n",
    "    payload = {\n",
    "        '_version': '1.0',\n",
    "        'user_id': data['id'],\n",
    "        'user_name': data['name']\n",
    "    }\n",
    "    return json.dumps(payload)\n",
    "\n",
    "def serialize_data_v2(data):\n",
    "    # New V2 format - fields renamed, added timestamp\n",
    "    payload = {\n",
    "        '_version': '2.0',\n",
    "        'userId': data['id'],\n",
    "        'displayName': data['name'],\n",
    "        'timestamp': data['time']\n",
    "    }\n",
    "    return json.dumps(payload)\n",
    "\n",
    "def process_data(serialized_string):\n",
    "    try:\n",
    "        loaded_data = json.loads(serialized_string)\n",
    "        version = loaded_data.get('_version')\n",
    "\n",
    "        if version == '1.0':\n",
    "            print(\"Processing V1.0 data:\")\n",
    "            # Adapt V1 data to internal representation\n",
    "            internal_repr = {\n",
    "                'id': loaded_data.get('user_id'),\n",
    "                'name': loaded_data.get('user_name'),\n",
    "                'time': None # V1 didn't have timestamp\n",
    "            }\n",
    "            return internal_repr\n",
    "            \n",
    "        elif version == '2.0':\n",
    "            print(\"Processing V2.0 data:\")\n",
    "            # Adapt V2 data to internal representation\n",
    "            internal_repr = {\n",
    "                'id': loaded_data.get('userId'),\n",
    "                'name': loaded_data.get('displayName'),\n",
    "                'time': loaded_data.get('timestamp') # Handle potential missing key\n",
    "            }\n",
    "            return internal_repr\n",
    "            \n",
    "        elif version is None:\n",
    "             print(\"Error: Data is missing '_version' field.\")\n",
    "             # Handle legacy data or raise error\n",
    "             return None\n",
    "        else:\n",
    "            print(f\"Error: Unsupported data version: {version}\")\n",
    "            # Raise error or attempt fallback\n",
    "            return None\n",
    "            \n",
    "    except json.JSONDecodeError:\n",
    "        print(\"Error: Invalid JSON input string.\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing data: {e}\")\n",
    "        return None\n",
    "\n",
    "# --- Example Usage ---\n",
    "user_data_v1 = {'id': 'usr123', 'name': 'Old Format'}\n",
    "user_data_v2 = {'id': 'usr456', 'name': 'New Format', 'time': '2024-01-01T10:00:00Z'}\n",
    "\n",
    "serialized_v1 = serialize_data_v1(user_data_v1)\n",
    "serialized_v2 = serialize_data_v2(user_data_v2)\n",
    "serialized_unknown = '{\"product\": \"widget\"}' # Missing version\n",
    "\n",
    "print(\"--- Processing serialized strings ---\")\n",
    "processed1 = process_data(serialized_v1)\n",
    "print(\"Result V1:\", processed1)\n",
    "\n",
    "processed2 = process_data(serialized_v2)\n",
    "print(\"Result V2:\", processed2)\n",
    "\n",
    "processed_unknown = process_data(serialized_unknown)\n",
    "print(\"Result Unknown:\", processed_unknown)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Error Handling and Fallbacks**\n",
    "\n",
    "Serialization and deserialization can fail (file not found, invalid format, network issues). Wrap these operations in `try...except` blocks and handle potential errors gracefully (e.g., log warnings, use default values, back up corrupted files)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install logging shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import logging\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')\n",
    "\n",
    "def default_app_settings():\n",
    "    \"\"\"Returns the default settings dictionary.\"\"\"\n",
    "    return {'theme': 'light', 'language': 'en', 'timeout': 30}\n",
    "\n",
    "def load_settings(filename='app_settings.json'):\n",
    "    \"\"\"Loads settings from JSON file with robust error handling.\"\"\"\n",
    "    try:\n",
    "        logging.info(f\"Attempting to load settings from {filename}...\")\n",
    "        with open(filename, 'r') as f:\n",
    "            settings = json.load(f)\n",
    "            # Basic validation: Is it a dictionary?\n",
    "            if not isinstance(settings, dict):\n",
    "                 logging.error(f\"Invalid settings format in {filename}: Expected a dictionary.\")\n",
    "                 raise ValueError(\"Settings format is not a dictionary\")\n",
    "            logging.info(f\"Settings loaded successfully from {filename}.\")\n",
    "            # Merge with defaults to ensure all keys are present\n",
    "            full_settings = default_app_settings()\n",
    "            full_settings.update(settings) # Loaded settings override defaults\n",
    "            return full_settings\n",
    "            \n",
    "    except FileNotFoundError:\n",
    "        logging.warning(f\"Settings file '{filename}' not found. Using default settings.\")\n",
    "        return default_app_settings()\n",
    "    except json.JSONDecodeError as e:\n",
    "        logging.error(f\"Invalid JSON syntax in '{filename}': {e}. Using default settings.\")\n",
    "        # Attempt to backup the corrupted file\n",
    "        backup_filename = f\"{filename}.corrupted_bak\"\n",
    "        try:\n",
    "            shutil.copy(filename, backup_filename)\n",
    "            logging.info(f\"Backed up corrupted file to {backup_filename}\")\n",
    "        except Exception as backup_err:\n",
    "            logging.error(f\"Could not backup corrupted file: {backup_err}\")\n",
    "        return default_app_settings()\n",
    "    except ValueError as e:\n",
    "        # Catch our custom validation error from above\n",
    "        logging.error(f\"Settings validation failed: {e}. Using default settings.\")\n",
    "        return default_app_settings()\n",
    "    except Exception as e:\n",
    "        logging.exception(f\"An unexpected error occurred while loading settings from {filename}: {e}. Using default settings.\")\n",
    "        return default_app_settings()\n",
    "\n",
    "# --- Test Cases ---\n",
    "settings_file = 'app_settings.json'\n",
    "\n",
    "# Test 1: File does not exist\n",
    "print(\"\\n--- Test 1: File Not Found ---\")\n",
    "if os.path.exists(settings_file): os.remove(settings_file)\n",
    "settings1 = load_settings(settings_file)\n",
    "print(\"Loaded settings:\", settings1)\n",
    "assert settings1 == default_app_settings()\n",
    "\n",
    "# Test 2: Valid JSON file\n",
    "print(\"\\n--- Test 2: Valid JSON ---\")\n",
    "valid_settings_data = {'theme': 'dark', 'timeout': 60}\n",
    "with open(settings_file, 'w') as f: json.dump(valid_settings_data, f)\n",
    "settings2 = load_settings(settings_file)\n",
    "expected_settings = default_app_settings()\n",
    "expected_settings.update(valid_settings_data) # Should merge\n",
    "print(\"Loaded settings:\", settings2)\n",
    "assert settings2 == expected_settings\n",
    "\n",
    "# Test 3: Invalid JSON file (syntax error)\n",
    "print(\"\\n--- Test 3: Invalid JSON Syntax ---\")\n",
    "with open(settings_file, 'w') as f: f.write('{\"theme\": \"dark\", invalid json')\n",
    "settings3 = load_settings(settings_file)\n",
    "print(\"Loaded settings:\", settings3)\n",
    "assert settings3 == default_app_settings()\n",
    "assert os.path.exists(settings_file + \".corrupted_bak\") # Check if backup was created\n",
    "if os.path.exists(settings_file + \".corrupted_bak\"): os.remove(settings_file + \".corrupted_bak\")\n",
    "\n",
    "# Test 4: Valid JSON, but wrong root type (list instead of dict)\n",
    "print(\"\\n--- Test 4: Valid JSON, Wrong Type ---\")\n",
    "with open(settings_file, 'w') as f: json.dump([1, 2, 3], f)\n",
    "settings4 = load_settings(settings_file)\n",
    "print(\"Loaded settings:\", settings4)\n",
    "assert settings4 == default_app_settings()\n",
    "\n",
    "# Clean up test file\n",
    "if os.path.exists(settings_file): os.remove(settings_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explained - Error Messages Generated by Previous Block** \n",
    "\n",
    "**The `ERROR` and `WARNING` messages you see in the first block of output are *expected* because:**\n",
    "\n",
    "1.  **Test 1:** The file doesn't exist, so `load_settings` correctly logs a `WARNING` and returns the default settings.\n",
    "2.  **Test 3:** The file contains invalid JSON, so `load_settings` correctly logs an `ERROR`, attempts a backup (logging `INFO`), and returns the default settings.\n",
    "3.  **Test 4:** The file contains valid JSON but the wrong type (list instead of dict), so `load_settings` correctly logs an `ERROR` (due to the `ValueError` raised and caught) and returns the default settings.\n",
    "\n",
    "The \"error\" isn't a program crash or a bug in the logic, but rather the expected logging output when the function encounters these specific error conditions designed by the tests.\n",
    "\n",
    "**Error Handling Demo**\n",
    "\n",
    "To run these tests *without seeing the expected WARNING/ERROR messages in the log output during the test execution*, you can temporarily raise the logging level around the specific calls that are *designed* to fail.\n",
    "\n",
    "Here's the modified code that suppresses these expected log messages during the tests:\n",
    "\n",
    "**Reasoning for the fix:**\n",
    "\n",
    "1.  **Identify Expected Logs:** Tests 1, 3, and 4 are specifically designed to trigger the error handling paths in `load_settings`, which correctly produce `WARNING` and `ERROR` level logs.\n",
    "2.  **Control Logging Level:** The most direct way to prevent these specific, expected logs from appearing *during the test run* without changing the function's core logging behavior is to temporarily change the logging level of the root logger.\n",
    "3.  **Implementation:**\n",
    "    *   Get the root logger: `logger = logging.getLogger()`.\n",
    "    *   Store its current level: `original_level = logger.level`.\n",
    "    *   Before calling `load_settings` in tests where failure logs are expected (Tests 1, 3, 4), set the level higher than `ERROR` (e.g., `logging.CRITICAL`). This tells the logger to ignore anything less severe than `CRITICAL`.\n",
    "    *   Immediately after the call, restore the logger's level to `original_level` so that subsequent logs (or logs in other parts of a larger application) behave as configured initially.\n",
    "\n",
    "The code in the next cell will now execute the tests, verify the correct fallback behavior via the `assert` statements, but will not print the `WARNING` or `ERROR` messages generated by the `load_settings` function during those specific failing test cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import logging\n",
    "import os\n",
    "import shutil\n",
    "import sys # Import sys to potentially redirect logging if needed, though level change is better\n",
    "\n",
    "# Configure logging - let's keep the basic config\n",
    "logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')\n",
    "# Get the root logger to control its level during tests\n",
    "logger = logging.getLogger()\n",
    "\n",
    "def default_app_settings():\n",
    "    \"\"\"Returns the default settings dictionary.\"\"\"\n",
    "    return {'theme': 'light', 'language': 'en', 'timeout': 30}\n",
    "\n",
    "def load_settings(filename='app_settings.json'):\n",
    "    \"\"\"Loads settings from JSON file with robust error handling.\"\"\"\n",
    "    try:\n",
    "        # This info log will still appear if the level is INFO\n",
    "        logging.info(f\"Attempting to load settings from {filename}...\")\n",
    "        with open(filename, 'r') as f:\n",
    "            settings = json.load(f)\n",
    "            # Basic validation: Is it a dictionary?\n",
    "            if not isinstance(settings, dict):\n",
    "                 # This error log will be suppressed if level is CRITICAL\n",
    "                 logging.error(f\"Invalid settings format in {filename}: Expected a dictionary.\")\n",
    "                 raise ValueError(\"Settings format is not a dictionary\")\n",
    "            # This info log will still appear if the level is INFO\n",
    "            logging.info(f\"Settings loaded successfully from {filename}.\")\n",
    "            # Merge with defaults to ensure all keys are present\n",
    "            full_settings = default_app_settings()\n",
    "            full_settings.update(settings) # Loaded settings override defaults\n",
    "            return full_settings\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        # This warning log will be suppressed if level is CRITICAL\n",
    "        logging.warning(f\"Settings file '{filename}' not found. Using default settings.\")\n",
    "        return default_app_settings()\n",
    "    except json.JSONDecodeError as e:\n",
    "        # This error log will be suppressed if level is CRITICAL\n",
    "        logging.error(f\"Invalid JSON syntax in '{filename}': {e}. Using default settings.\")\n",
    "        # Attempt to backup the corrupted file\n",
    "        backup_filename = f\"{filename}.corrupted_bak\"\n",
    "        try:\n",
    "            shutil.copy(filename, backup_filename)\n",
    "            # This info log will still appear if the level is INFO\n",
    "            logging.info(f\"Backed up corrupted file to {backup_filename}\")\n",
    "        except Exception as backup_err:\n",
    "             # This error log will be suppressed if level is CRITICAL\n",
    "            logging.error(f\"Could not backup corrupted file: {backup_err}\")\n",
    "        return default_app_settings()\n",
    "    except ValueError as e:\n",
    "        # Catch our custom validation error from above\n",
    "        # This error log will be suppressed if level is CRITICAL\n",
    "        logging.error(f\"Settings validation failed: {e}. Using default settings.\")\n",
    "        return default_app_settings()\n",
    "    except Exception as e:\n",
    "        # This exception log might still appear depending on the error level\n",
    "        logging.exception(f\"An unexpected error occurred while loading settings from {filename}: {e}. Using default settings.\")\n",
    "        return default_app_settings()\n",
    "\n",
    "# --- Test Cases ---\n",
    "settings_file = 'app_settings.json'\n",
    "\n",
    "# Store original logging level\n",
    "original_level = logger.level\n",
    "\n",
    "# Test 1: File does not exist\n",
    "print(\"\\n--- Test 1: File Not Found ---\")\n",
    "if os.path.exists(settings_file): os.remove(settings_file)\n",
    "# Suppress expected WARNING for this specific call\n",
    "logger.setLevel(logging.CRITICAL)\n",
    "settings1 = load_settings(settings_file)\n",
    "# Restore original level\n",
    "logger.setLevel(original_level)\n",
    "print(\"Loaded settings:\", settings1)\n",
    "assert settings1 == default_app_settings()\n",
    "\n",
    "# Test 2: Valid JSON file\n",
    "print(\"\\n--- Test 2: Valid JSON ---\")\n",
    "valid_settings_data = {'theme': 'dark', 'timeout': 60}\n",
    "with open(settings_file, 'w') as f: json.dump(valid_settings_data, f)\n",
    "# No need to suppress logs here, expected to succeed cleanly\n",
    "settings2 = load_settings(settings_file)\n",
    "print(\"Loaded settings:\", settings2)\n",
    "expected_settings = default_app_settings()\n",
    "expected_settings.update(valid_settings_data) # Should merge\n",
    "assert settings2 == expected_settings\n",
    "\n",
    "# Test 3: Invalid JSON file (syntax error)\n",
    "print(\"\\n--- Test 3: Invalid JSON Syntax ---\")\n",
    "with open(settings_file, 'w') as f: f.write('{\"theme\": \"dark\", invalid json')\n",
    "# Suppress expected ERROR/INFO logs for this specific call\n",
    "logger.setLevel(logging.CRITICAL)\n",
    "settings3 = load_settings(settings_file)\n",
    "# Restore original level\n",
    "logger.setLevel(original_level)\n",
    "print(\"Loaded settings:\", settings3)\n",
    "assert settings3 == default_app_settings()\n",
    "# We can still check if the backup file was created *silently*\n",
    "assert os.path.exists(settings_file + \".corrupted_bak\") # Check if backup was created\n",
    "if os.path.exists(settings_file + \".corrupted_bak\"): os.remove(settings_file + \".corrupted_bak\")\n",
    "\n",
    "# Test 4: Valid JSON, but wrong root type (list instead of dict)\n",
    "print(\"\\n--- Test 4: Valid JSON, Wrong Type ---\")\n",
    "with open(settings_file, 'w') as f: json.dump([1, 2, 3], f)\n",
    "# Suppress expected ERROR for this specific call\n",
    "logger.setLevel(logging.CRITICAL)\n",
    "settings4 = load_settings(settings_file)\n",
    "# Restore original level\n",
    "logger.setLevel(original_level)\n",
    "print(\"Loaded settings:\", settings4)\n",
    "assert settings4 == default_app_settings()\n",
    "\n",
    "# Clean up test file\n",
    "if os.path.exists(settings_file):\n",
    "    os.remove(settings_file)\n",
    "    print(f\"\\nCleaned up {settings_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Testing Serialization Code**\n",
    "\n",
    "Thoroughly test your serialization and deserialization logic:\n",
    "*   **Round-trip tests:** Serialize an object, deserialize it, and assert it's identical to the original.\n",
    "*   **Edge cases:** Test with empty dictionaries, nested structures, special values (None, NaN, infinity if applicable), different data types.\n",
    "*   **Custom types:** If using custom encoders/decoders, ensure they handle all expected types correctly.\n",
    "*   **Error handling:** Test how your code behaves with corrupted or invalid input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unittest\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "# Assume DateTimeEncoder and datetime_decoder are defined as in Notebook 2\n",
    "class DateTimeEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, datetime):\n",
    "            return {'__datetime__': obj.isoformat()} \n",
    "        return super().default(obj)\n",
    "\n",
    "def datetime_decoder(dct):\n",
    "    if '__datetime__' in dct:\n",
    "        return datetime.fromisoformat(dct['__datetime__'])\n",
    "    return dct\n",
    "\n",
    "# --- Unit Test Class --- \n",
    "class TestDictionarySerialization(unittest.TestCase):\n",
    "\n",
    "    def test_json_round_trip_simple(self):\n",
    "        \"\"\"Test basic JSON serialize/deserialize round trip.\"\"\"\n",
    "        original = {'name': 'Test', 'value': 123, 'active': True, 'items': [1, None, 'abc']}\n",
    "        serialized = json.dumps(original)\n",
    "        deserialized = json.loads(serialized)\n",
    "        self.assertEqual(original, deserialized, \"Simple JSON round trip failed\")\n",
    "\n",
    "    def test_json_round_trip_nested(self):\n",
    "        \"\"\"Test nested JSON serialize/deserialize round trip.\"\"\"\n",
    "        original = {'a': 1, 'b': {'c': [2, 3], 'd': 'nested'}, 'e': []}\n",
    "        serialized = json.dumps(original)\n",
    "        deserialized = json.loads(serialized)\n",
    "        self.assertEqual(original, deserialized, \"Nested JSON round trip failed\")\n",
    "\n",
    "    def test_json_custom_datetime_round_trip(self):\n",
    "        \"\"\"Test JSON round trip with custom datetime encoder/decoder.\"\"\"\n",
    "        now = datetime.now()\n",
    "        # Truncate microseconds for consistent comparison after ISO format round trip\n",
    "        now = now.replace(microsecond=0) \n",
    "        original = {'event': 'Meeting', 'time': now, 'participants': ['A', 'B']}\n",
    "        \n",
    "        serialized = json.dumps(original, cls=DateTimeEncoder)\n",
    "        deserialized = json.loads(serialized, object_hook=datetime_decoder)\n",
    "        \n",
    "        self.assertEqual(original, deserialized, \"Custom datetime JSON round trip failed\")\n",
    "        self.assertIsInstance(deserialized['time'], datetime, \"Datetime type not restored\")\n",
    "\n",
    "    def test_pickle_round_trip_complex(self):\n",
    "        \"\"\"Test Pickle round trip with complex types (set, datetime).\"\"\"\n",
    "        import pickle\n",
    "        now = datetime.now()\n",
    "        original = {'id': 10, 'tags': {'urgent', 'dev'}, 'timestamp': now}\n",
    "        \n",
    "        serialized = pickle.dumps(original)\n",
    "        deserialized = pickle.loads(serialized)\n",
    "        \n",
    "        self.assertEqual(original, deserialized, \"Complex Pickle round trip failed\")\n",
    "        self.assertIsInstance(deserialized['tags'], set, \"Set type not restored\")\n",
    "        self.assertIsInstance(deserialized['timestamp'], datetime, \"Datetime type not restored\")\n",
    "\n",
    "# --- Run the tests --- \n",
    "# In a real scenario, you'd run this from the command line using 'python -m unittest your_test_module.py'\n",
    "# Here, we run it directly within the notebook environment.\n",
    "print(\"Running serialization unit tests...\")\n",
    "suite = unittest.TestSuite()\n",
    "suite.addTest(unittest.makeSuite(TestDictionarySerialization))\n",
    "runner = unittest.TextTestRunner()\n",
    "runner.run(suite)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "Mastering dictionary serialization is crucial for building robust Python applications. We've covered:\n",
    "\n",
    "*   **Why and What:** The need for serialization and basic concepts.\n",
    "*   **Formats:** JSON, Pickle, YAML, MessagePack, HDF5 – their strengths and weaknesses.\n",
    "*   **Advanced Techniques:** Handling custom types, optimizing performance, managing large data.\n",
    "*   **Applications:** Configuration, APIs, data persistence (like caching or inventory).\n",
    "*   **Security & Best Practices:** The dangers of `pickle.loads`, the necessity of input validation, versioning, error handling, and testing.\n",
    "\n",
    "By choosing the right serialization format for your task and following best practices, especially regarding security and error handling, you can effectively persist, exchange, and manage dictionary-based data in your Python projects."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
